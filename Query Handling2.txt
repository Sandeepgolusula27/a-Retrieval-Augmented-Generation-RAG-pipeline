# Embed the user query
query = "What are the key research programs at 
Stanford University?"
query_embedding = model.encode([query])
# Retrieve relevant chunks
D, I = index.search(query_embedding, k=5) # 
Retrieve top 5 matches
relevant_chunks = [content_chunks[i] for i in I[0]]
# Combine retrieved chunks for context
context = "\n".join(relevant_chunks)
# LLM input
llm_input = f"Context:\n{context}\n\nQuestion: 
{query}\nAnswer in detail."